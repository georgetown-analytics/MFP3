{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Text</th>\n",
       "      <th>Company</th>\n",
       "      <th>Industry</th>\n",
       "      <th>IPO Period</th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>Source Tier</th>\n",
       "      <th>PositiveScore</th>\n",
       "      <th>NegativeScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FACEBOOK ROLLS OUT NEW ADS TO WOO MADISON AVEN...</td>\n",
       "      <td>Aberdeen American News</td>\n",
       "      <td>2012-02-29</td>\n",
       "      <td>358</td>\n",
       "      <td>Facebook wooed Madison Avenue on Wednesday wit...</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Technology</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FACEBOOK PRICES ITS STOCK AT $38 A SHARE FOR IPO</td>\n",
       "      <td>Aberdeen American News</td>\n",
       "      <td>2012-05-17</td>\n",
       "      <td>515</td>\n",
       "      <td>Facebook Inc. priced its shares in its initial...</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Technology</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REGULATORS LOOKING INTO MORGAN STANLEY ROLE IN...</td>\n",
       "      <td>Aberdeen American News</td>\n",
       "      <td>2012-05-22</td>\n",
       "      <td>288</td>\n",
       "      <td>NEW YORK -- Securities regulators are amping u...</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FACEBOOK, MORGAN STANLEY FACE CLASS-ACTION SUI...</td>\n",
       "      <td>Aberdeen American News</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>583</td>\n",
       "      <td>WASHINGTON -- A class-action lawsuit was filed...</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FAQ: Facebook's IPO</td>\n",
       "      <td>Abilene Reporter-News</td>\n",
       "      <td>2012-02-03</td>\n",
       "      <td>947</td>\n",
       "      <td>The most anticipated IPO since Google is one s...</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Technology</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline                  Source  \\\n",
       "0  FACEBOOK ROLLS OUT NEW ADS TO WOO MADISON AVEN...  Aberdeen American News   \n",
       "1   FACEBOOK PRICES ITS STOCK AT $38 A SHARE FOR IPO  Aberdeen American News   \n",
       "2  REGULATORS LOOKING INTO MORGAN STANLEY ROLE IN...  Aberdeen American News   \n",
       "3  FACEBOOK, MORGAN STANLEY FACE CLASS-ACTION SUI...  Aberdeen American News   \n",
       "4                                FAQ: Facebook's IPO   Abilene Reporter-News   \n",
       "\n",
       "        Date  Word Count                                               Text  \\\n",
       "0 2012-02-29         358  Facebook wooed Madison Avenue on Wednesday wit...   \n",
       "1 2012-05-17         515  Facebook Inc. priced its shares in its initial...   \n",
       "2 2012-05-22         288  NEW YORK -- Securities regulators are amping u...   \n",
       "3 2012-05-23         583  WASHINGTON -- A class-action lawsuit was filed...   \n",
       "4 2012-02-03         947  The most anticipated IPO since Google is one s...   \n",
       "\n",
       "    Company    Industry  IPO Period  Day of Week  Source Tier  PositiveScore  \\\n",
       "0  Facebook  Technology           1            4            4            0.0   \n",
       "1  Facebook  Technology           1            5            4            0.0   \n",
       "2  Facebook  Technology           2            3            4            0.0   \n",
       "3  Facebook  Technology           2            4            4            0.0   \n",
       "4  Facebook  Technology           1            6            4            0.0   \n",
       "\n",
       "   NegativeScore  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../../../Updated_DataFrame.xlsx', 'SentimentScore', usecols=12)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ticker'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_ticker = {\n",
    "    'Facebook': 'FB',\n",
    "    'LinkedIn': 'LNKD',\n",
    "    'Groupon': 'GRPN',\n",
    "    'Snapchat': 'SNAP',\n",
    "    'Twitter': 'TWTR',\n",
    "    'Alibaba': 'BABA',\n",
    "    'Etsy': 'ETSY',\n",
    "    'Fitbit': 'FIT',\n",
    "    'Workday': 'WDAY',\n",
    "    'GoPro': 'GPRO',\n",
    "    'Blue Apron': 'APRN',\n",
    "    'Ferrari': 'RACE',\n",
    "    'General Motors': 'GM',\n",
    "    'Shake Shack': 'SHAK',\n",
    "    'Stitch Fix': 'SFIX',\n",
    "    'Tesls': 'TSLA',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ticker'] = df['Company'].map(company_ticker)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_prices = pd.read_csv('IPO_MKT_PRICES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_prices = mkt_prices.rename(columns={'Symbol': 'Ticker'})\n",
    "mkt_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_prices['Date'] = pd.to_datetime(mkt_prices['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(df, mkt_prices, on=['Date', 'Ticker'], how='left')\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipo_info = pd.read_csv('IPO_INFO.csv', sep='|', index_col=False)\n",
    "ipo_info = ipo_info.rename(columns={'Symbol': 'Ticker', 'Date': 'Offer Date'})\n",
    "ipo_info['Offer Date'] = pd.to_datetime(ipo_info['Offer Date'])\n",
    "ipo_info.drop(['Performed'], axis=1, inplace=True)\n",
    "ipo_info.drop(['Ratings'], axis=1, inplace=True)\n",
    "ipo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers = dict(zip(ipo_info['Ticker'], ipo_info['Managers']))\n",
    "managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in managers.items():\n",
    "    managers[k] = (v.split('/ '))\n",
    "managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers_df = pd.DataFrame.from_dict(managers, orient='index')\n",
    "managers_df.columns = ('Mngr1', 'Mngr2', 'Mngr3', 'Mngr4', 'Mngr5', 'Mngr6')\n",
    "managers_df.loc['FB'][2] = 'Goldman Sachs'\n",
    "managers_df.loc['LNKD'][2] = 'J.P.Morgan'\n",
    "managers_df.loc['LNKD'][1] = 'BofA Merrill Lynch'\n",
    "managers_df.loc['GRPN'][1] = 'Goldman Sachs'\n",
    "managers_df.loc['SNAP'][1] = 'Goldman Sachs'\n",
    "managers_df.loc['BABA'][5] = 'Citigroup'\n",
    "managers_df.loc['FIT'][2] = 'BofA Merrill Lynch'\n",
    "managers_df.loc['WDAY'][1] = 'Goldman Sachs'\n",
    "managers_df.loc['GM'][3] = 'Citigroup'\n",
    "managers_df.loc['SFIX'][1] = 'J.P.Morgan'\n",
    "managers_df.loc['TSLA'][0] = 'Goldman Sachs'\n",
    "#managers_df.reset_index(level=0, inplace=True)\n",
    "managers_df.index.name = 'Ticker'\n",
    "managers_df.fillna(value=nan, inplace=True)\n",
    "managers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ipo_info = pd.merge(ipo_info, managers_df, on='Ticker')\n",
    "del new_ipo_info['Managers']\n",
    "new_ipo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ipo_info['Offer Date +90'] = new_ipo_info['Offer Date'] + timedelta(days=90)\n",
    "new_ipo_info.to_csv('NEW_IPO_INFO.csv')\n",
    "new_ipo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ipo_info = pd.merge(new_ipo_info,\n",
    "                       mkt_prices[['Date', 'Ticker', 'Close']],\n",
    "                       left_on = ['Offer Date +90', 'Ticker'],\n",
    "                       right_on = ['Date', 'Ticker'],\n",
    "                       how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ipo_info = new_ipo_info.rename(columns={'Close': 'Close +90'})\n",
    "new_ipo_info['% Px Chng +90'] = (new_ipo_info['Close +90'] - new_ipo_info['1st Day Close'])/new_ipo_info['1st Day Close']\n",
    "new_ipo_info['Label'] = ''\n",
    "\n",
    "new_ipo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ipo_info['Offer Date +180'] = new_ipo_info['Offer Date'] + timedelta(days=180)\n",
    "new_ipo_info.to_csv('NEW_IPO_INFO.csv')\n",
    "new_ipo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to change 2010-12-26 to 2010-12-28 because it is a Sunday also blizard hit so opted to choose Tuesday rather than Monday\n",
    "\n",
    "new_ipo_info['Offer Date +180'].replace(to_replace=pd.to_datetime('2010-12-26'), value=pd.to_datetime('2010-12-28'), inplace=True)\n",
    "new_ipo_info.iloc[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ipo_info = pd.merge(new_ipo_info,\n",
    "                       mkt_prices[['Date', 'Ticker', 'Close']],\n",
    "                       left_on = ['Offer Date +180', 'Ticker'],\n",
    "                       right_on = ['Date', 'Ticker'],\n",
    "                       how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ipo_info = new_ipo_info.rename(columns={'Close': 'Close +180'})\n",
    "new_ipo_info['% Px Chng +180'] = (new_ipo_info['Close +180'] - new_ipo_info['1st Day Close'])/new_ipo_info['1st Day Close']\n",
    "new_ipo_info['Label180'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ipo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(new_ipo_info)):\n",
    "    if new_ipo_info['% Px Chng +90'][i] < -0.02:\n",
    "        new_ipo_info['Label'][i] = 'Negative'\n",
    "    elif new_ipo_info['% Px Chng +90'][i] > 0.02:\n",
    "        new_ipo_info['Label'][i] = 'Positive'\n",
    "    else:\n",
    "        new_ipo_info['Label'][i] = 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(new_ipo_info)):\n",
    "    if new_ipo_info['% Px Chng +180'][i] < -0.02:\n",
    "        new_ipo_info['Label180'][i] = 'Negative'\n",
    "    elif new_ipo_info['% Px Chng +180'][i] > 0.02:\n",
    "        new_ipo_info['Label180'][i] = 'Positive'\n",
    "    else:\n",
    "        new_ipo_info['Label180'][i] = 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_df = pd.merge(new_df, new_ipo_info, on=['Ticker'])\n",
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get story text file for Naive Bayes\n",
    "\n",
    "text = new_df[['Text', 'Label', 'Label180']]\n",
    "text = text[pd.notnull(text['Text'])]\n",
    "text.info()\n",
    "text.to_csv('Text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = new_df.rename(columns={'Date_x': 'Date'})\n",
    "#del new_df['Text']\n",
    "\n",
    "# These are the dates from the new_ipo_info dataframe same as Close +90 and Close +180\n",
    "new_df = new_df.drop(['Text', 'Date_x', 'Date_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding Alam's sentiment scores\n",
    "\n",
    "alam_score = pd.read_csv('Initial-Data-Set-With-Sentiment.csv')\n",
    "alam_scores = alam_score[['neutral', 'weakneg', 'weakpos', 'strongpos', 'strongneg']]\n",
    "new_df = pd.merge(new_df, alam_scores, left_index=True, right_index=True)\n",
    "new_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    'Headline',\n",
    "    'Source',\n",
    "    'Date',\n",
    "    'Word Count',\n",
    "    'Company',\n",
    "    'Industry',\n",
    "    'IPO Period',\n",
    "    'Day of Week',\n",
    "    'Source Tier',\n",
    "    'PositiveScore',\n",
    "    'NegativeScore',\n",
    "    'Ticker',\n",
    "    'Close',\n",
    "    'High',\n",
    "    'Low',\n",
    "    'Open',\n",
    "    'Volume',\n",
    "    'Offer Date',\n",
    "    'Issuer',\n",
    "    'Offer Price',\n",
    "    'Open Price',\n",
    "    '1st Day Close',\n",
    "    '1st Day % Px Chng',\n",
    "    '$ Change Opening',\n",
    "    '$ Change Close',\n",
    "    'Mngr1',\n",
    "    'Mngr2',\n",
    "    'Mngr3',\n",
    "    'Mngr4',\n",
    "    'Mngr5',\n",
    "    'Mngr6',\n",
    "    'Offer Date +90',\n",
    "    'Close +90',\n",
    "    '% Px Chng +90',\n",
    "    'Label',\n",
    "    'Offer Date +180',\n",
    "    'Close +180',\n",
    "    '% Px Chng +180',\n",
    "    'Label180',\n",
    "    'neutral',\n",
    "    'weakneg',\n",
    "    'weakpos',\n",
    "    'strongpos',\n",
    "    'strongneg'\n",
    "]\n",
    "new_df.columns = names\n",
    "#new_df.head(50)\n",
    "#new_df.to_csv('features.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup context and style \n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(data=new_df[['Word Count','IPO Period', 'Day of Week', 'Source Tier', 'PositiveScore', 'NegativeScore',\n",
    "#                          '1st Day % Px Chng', 'Label', 'neutral', 'weakneg', 'weakpos', 'strongpos', 'strongneg']], hue='Label', diag_kind='kde')\n",
    "sns.pairplot(data=new_df[['Word Count', 'IPO Period', 'Source Tier', 'PositiveScore', 'NegativeScore', 'Label180',\n",
    "             'neutral', 'weakneg', 'weakpos', 'strongpos', 'strongneg']], hue='Label180', diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Source', 'Date', 'Word Count', 'Company', 'Industry', 'IPO Period', 'Day of Week', 'Source Tier',\n",
    "           'PositiveScore', 'NegativeScore', '1st Day % Px Chng', 'Mngr1']\n",
    "\n",
    "target = ['Label180']\n",
    "#X = new_df[features]\n",
    "X = new_df[['Source','Word Count', 'Industry', 'PositiveScore', 'NegativeScore', 'Source Tier', 'Mngr1', 'neutral',\n",
    "           'weakneg', 'weakpos', 'strongpos', 'strongneg']]\n",
    "y = new_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "class EncodeCategorical(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encodes a specified list of columns or all columns if None. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, columns=None):\n",
    "        self.columns  = [col for col in columns] \n",
    "        self.encoders = None\n",
    "    \n",
    "    def fit(self, data, target=None):\n",
    "        \"\"\"\n",
    "        Expects a data frame with named columns to encode. \n",
    "        \"\"\"\n",
    "        # Encode all columns if columns is None\n",
    "        if self.columns is None:\n",
    "            self.columns = data.columns \n",
    "        \n",
    "        # Fit a label encoder for each column in the data frame\n",
    "        self.encoders = {\n",
    "            column: LabelEncoder().fit(data[column])\n",
    "            for column in self.columns \n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Uses the encoders to transform a data frame. \n",
    "        \"\"\"\n",
    "        output = data.copy()\n",
    "        for column, encoder in self.encoders.items():\n",
    "            output[column] = encoder.transform(data[column])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def model_selection(X, y, estimator):\n",
    "    \"\"\"\n",
    "    Test various estimators.\n",
    "    \"\"\" \n",
    "    y = LabelEncoder().fit_transform(y.values.ravel())\n",
    "    model = Pipeline([\n",
    "         ('label_encoding', EncodeCategorical(X.keys())), \n",
    "         ('one_hot_encoder', OneHotEncoder()), \n",
    "         ('estimator', estimator)\n",
    "    ])\n",
    "\n",
    "    # Instantiate the classification model and visualizer\n",
    "    model.fit(X, y)  \n",
    "    \n",
    "    expected  = y\n",
    "    predicted = model.predict(X)\n",
    "    \n",
    "    # Compute and return the F1 score (the harmonic mean of precision and recall)\n",
    "    # Needed to add average='micro' with 180+ labels since they were not binary; default is 'binary'\n",
    "    return (f1_score(expected, predicted, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection(X, y, LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection(X, y, SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection(X, y, SGDClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "\n",
    "\n",
    "def visual_model_selection(X, y, estimator):\n",
    "    \"\"\"\n",
    "    Test various estimators.\n",
    "    \"\"\" \n",
    "    y = LabelEncoder().fit_transform(y.values.ravel())\n",
    "    model = Pipeline([\n",
    "         ('label_encoding', EncodeCategorical(X.keys())), \n",
    "         ('one_hot_encoder', OneHotEncoder()), \n",
    "         ('estimator', estimator)\n",
    "    ])\n",
    "\n",
    "    # Instantiate the classification model and visualizer\n",
    "    visualizer = ClassificationReport(model, classes=['Negative', 'Neutral', 'Positive'])\n",
    "    visualizer.fit(X, y)  \n",
    "    visualizer.score(X, y)\n",
    "    visualizer.poof()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_model_selection(X, y, LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_model_selection(X, y, SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_model_selection(X, y, SGDClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
